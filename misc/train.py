from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
import pickle

# Пример тренировочных данных
texts = [
    # Поломки (мебель, двери, шкафы)
    "сломалась парта в 10 кабинете",
    "стул расшатался в 12 кабинете",
    "сломалась дверь в мастерской",
    "разбился шкаф в кабинете 7",
    "вентилятор сломан в 3 кабинете",
    "стол сломан в 5 кабинете",
    "стул поломан нахрен",
    "парта сломана, нахуй",

    # Электроника
    "не работает лампа в 4 кабинете",
    "перегорела лампочка в мастерской",
    "проектор не включается в кабинете 5",
    "монитор сломался в 12 кабинете",
    "компьютер не работает в 7 кабинете",
    "розетка не работает в кабинете 9",
    "свет не включается, ёб твою мать",
    "лампа потухла, пиздец",

    # Уборка
    "грязно в 54 кабинете",
    "мусор на полу в коридоре",
    "воняет в туалете",
    "в туалете насрано",
    "пол мокрый и скользкий",
    "класс не убран после урока",
    "грязь на столах, ёб твою мать",
    "убрать этот срач в кабинете 12",

    # Другое
    "трудовик спился(",
    "учитель кричит как пиздец",
    "гойда",
    "непонятно что происходит в мастерской",
    "нахуй весь этот ебучий проектор",
    "бля, снова какие-то проблемы"
]

labels = [
    # Поломки
    "Поломки", "Поломки", "Поломки", "Поломки", "Поломки", "Поломки", "Поломки", "Поломки",

    # Электроника
    "Электроника", "Электроника", "Электроника", "Электроника", "Электроника", "Электроника", "Электроника", "Электроника",

    # Уборка
    "Уборка", "Уборка", "Уборка", "Уборка", "Уборка", "Уборка", "Уборка", "Уборка",

    # Другое
    "Другое", "Другое", "Другое", "Другое", "Другое", "Другое"
]

# Векторизация текста
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(texts)

# Модель Naive Bayes
model = MultinomialNB()
model.fit(X, labels)

# Сохраняем модель и векторизатор
with open("category_model.pkl", "wb") as f:
    pickle.dump((vectorizer, model), f)

print("Модель обучена и сохранена.")

